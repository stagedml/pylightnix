MNIST Demo
==========

[Complete source of the demo](./MNIST.py)

In this document we show how
[Pylightnix](https://github.com/stagedml/pylightnix) can be used in machine
learning applications. We focus on `inplace` subset of [Pylightnix
API](https://github.com/stagedml/pylightnix/blob/master/docs/Reference.md) which
is a bit simpler than it's default functional API, at the cost of relying on an
internal global state.

We will use Pylightnix in well-known MNIST classifier application. [TensorFlow
2.0](https://www.tensorflow.org) framework is required to run this demo.

## The problem

In MNIST problem, we generally have to write an application performing image
classification. The format of input images is defined by the [MNIST
dataset](http://yann.lecun.com/exdb/mnist/). It is a set of 28x28-sized images
of handwritten digits, part of them are labaled, labels say what digit do we see
on given image. Our classifier needs to label the unlabeled part of the dataset.

To solve this problem with a Deep Learning approach, we typically write an
application which relies on certain parameters. Some of them are pre-defined (we
call them just 'parameters'), others are initially unknown to us (we call them
*Weights*). We then adjust the weights with an algorithm known as 'training',
using existing labels as an input data. This process makes the classification
work better and better. Eventually, we get a snapshot of weights which work best
for our dataset and which we hope will work well for other similar images. This
snapshot is called a *Checkpoint*. We have to save the checkpoint to use it in
the imaginary 'production' of our application.

## Implementation

Lets plan the usage of data. As one may see, we need a place to keep the
*Dataset* during training and a place to put the final *Checkpoint* when it is
ready. Also it is often a good idea to save pre-defined *Parameters* somewhere
to be able to re-produce the training if needed. Let's see how does Pylightnix
help with that.

First, let's prepare a separate storage for this demo.

```python
from shutil import rmtree
from pylightnix import store_initialize
rmtree('/tmp/pylightnix_mnist_demo', ignore_errors=True)
store_initialize(custom_store='/tmp/pylightnix_mnist_demo', custom_tmp='/tmp')
```

Now we are ready to code.

### Stage 1: the dataset

MNIST is a well-known dataset, it is available in many places on the Internet.
We may pick the closest one and download a single file `mnist.npz`.


```python, complete=True, wrap=False
from pylightnix import DRef, instantiate_inplace, fetchurl

mnist_dataset:DRef = \
  instantiate_inplace(
    fetchurl,
    name='mnist',
    mode='as-is',
    url='https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz',
    sha256='731c5ac602752760c8e48fbffcf8c3b850d9dc2a2aedcf2cc48468fc17b673d1')

print(mnist_dataset)

```

What did we do? We created `mnist_dataset` variable of type
[DRef](./../Reference.md#pylightnix.types.DRef) which takes a reference to a
**Derivation** of `fetchurl` builtin stage. The existance of DRef means that: a)
the configuration of it's stage does exist in the storage and it doesn't
contain critical errors like invalid links. b) Pylighnix knows how to
**Realize** this stage, i.e. what Python function to call on it and which
directory to collect the output files from.


### Stage 2: the recognizer

#### Stage configuration

We need some parameters to run the training. A natural place for them is the
configuration of our new stage.

```python
from pylightnix import Config, mkconfig

def mnist_config()->Config:
  dataset = [mnist_dataset, 'mnist.npz']
  learning_rate = 1e-3
  num_epoches = 1
  return mkconfig(locals())
```

#### Stage realization

Here comes the training itself. We access the configuration by calling
`build_cattrs` function which returns an object with configuratin attributes.

Attributes like strings or floats may be used directly, but refpaths have to be
**dereferenced** first. So we access our dataset by calling `build_path(b,
c.dataset)` function.

```python
from pylightnix import ( Build, build_outpath, build_cattrs, build_path )
from os.path import join
from numpy import load
from tensorflow.keras.models import ( Sequential )
from tensorflow.keras.layers import ( Conv2D, MaxPool2D, Dropout, Flatten, Dense )
from tensorflow.keras.utils import ( to_categorical )
from tensorflow.keras.backend import image_data_format


def mnist_build(b:Build)->None:
  o = build_outpath(b)
  c = build_cattrs(b)

  with load(build_path(b, c.dataset), allow_pickle=True) as f:
    x_train, y_train = f['x_train'], f['y_train']
    x_test, y_test = f['x_test'], f['y_test']

  x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32') / 255
  y_train = to_categorical(y_train, 10)

  x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32') / 255
  y_test = to_categorical(y_test, 10)


  print('x_train shape:', x_train.shape)
  print(x_train.shape[0], 'train samples')
  print(x_test.shape[0], 'test samples')

  model = Sequential()
  model.add(Conv2D(32, kernel_size=(3, 3), activation = 'relu', input_shape = (28,28,1)))
  model.add(Conv2D(64, (3, 3), activation = 'relu'))
  model.add(MaxPool2D(pool_size = (2,2)))
  model.add(Dropout(0.25))
  model.add(Flatten())
  model.add(Dense(128, activation = 'relu'))
  model.add(Dropout(0.5))
  model.add(Dense(10, activation = 'softmax'))

  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])
  model.fit(x_train, y_train, batch_size = 32, epochs = c.num_epoches, verbose = 0)
  accuracy = model.evaluate(x_test, y_test, verbose = 0)[-1]
  model.save_weights(join(o, 'weights.h5'), save_format='h5')
  with open(join(o,'accuracy.txt'),'w') as f:
    f.write(str(accuracy))
```

At the end of the training, we are going to save important artifacts into
the **output folder** `o`:
- Checkpoint of a model, see `model.save_weights(join(o, 'weights.h5')...)`
- Evaluation accuracy, see `open(join(o,'accuracy.txt'),'w')`

#### Stage matching

In this section we will prepare to deal with multiple realizations of our stage.
Training of machine learning model is generally a non-determenistic process,
were results may change from run to run.

Pylightnix is aware of this fact. We may deal with it by specifying a
[matcher](./../Reference.md#pylightnix.types.Matcher) function, that will choose
the best realization among available.

In the machine learning domain, we often want to pick the realizations of mode
weights and we surely want a model with the best accuracy.

```python
from pylightnix import match_best

def mnist_match():
  return match_best('accuracy.txt')
```

Matchers should met the following important requirement:

- They should be pure, i.e. results should depend only on the information
  contained in the input realizations (so, inside no global variables and no
  randoms are allowed)


#### Putting it all together

Finally, we register our stage by calling `mkdrv` function. As before,
`instantiate` provides us with a derivation reference. This reference is a proof
that safety checkes are done. Now we are ready for actual training.

```python, complete=True, wrap=False

from pylightnix import mkdrv, build_wrapper

def model(m)->DRef:
  return mkdrv(m, mnist_config(), mnist_match(), build_wrapper(mnist_build))

mnist_model = instantiate_inplace(model)
print(mnist_model)
```

To demonstrate how does matching work, let's ask Pylightnix to make more than
one realization of our stage. We call `realize_inplace` function with
`force_rebuild` argument two times. Without `force_rebuild`, the second call to
realize would have returned an already existing realization obtained after the
first call.

```python, complete=True, wrap=False
from pylightnix import realize_inplace

mnist1 = realize_inplace(mnist_model, force_rebuild=[mnist_model])
mnist2 = realize_inplace(mnist_model, force_rebuild=[mnist_model])
print(mnist1)
print(mnist2)

```

Lets see which model is better. Pylightnix comes with a set of simple bash-like oneliners
designe to be used for quick manual checks.

```python, term=True,wrap=False
from pylightnix import lsref, catref

lsref(mnist_model)
catref(mnist1,['accuracy.txt'])
catref(mnist2,['accuracy.txt'])
```

Clearly,
<%'mnist1' if float(catref(mnist1,['accuracy.txt'])[0])>float(catref(mnist2,['accuracy.txt'])[0]) else 'mnist2' %>
shows slightly better results. Our matcher thinks the same, so if we don't force
Pylightnix to produce more realizations, it will return it as a better match:

```python, complete=True, wrap=False
mnistX = realize_inplace(mnist_model)
print(mnistX)
```


### Stage 3: the application


(TODO)

